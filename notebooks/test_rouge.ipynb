{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install absl-py nltk rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prompting.rewards import calculate_rouge_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.8333333333333334,\n",
       "   'p': 0.8333333333333334,\n",
       "   'f': 0.8333333283333335},\n",
       "  'rouge-2': {'r': 0.4, 'p': 0.4, 'f': 0.3999999950000001},\n",
       "  'rouge-l': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001}},\n",
       " {'rouge-1': {'r': 0.8333333333333334,\n",
       "   'p': 0.8333333333333334,\n",
       "   'f': 0.8333333283333335},\n",
       "  'rouge-2': {'r': 0.4, 'p': 0.4, 'f': 0.3999999950000001},\n",
       "  'rouge-l': {'r': 0.5, 'p': 0.5, 'f': 0.4999999950000001}}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "\n",
    "rouge = Rouge()\n",
    "# Define your reference and hypothesis texts\n",
    "reference_text = [\"The capital of Texas is Austin.\", \"Austin is the capital of Texas.\"]\n",
    "hypothesis_text = [\"Austin is the capital of Texas.\", \"The capital of Texas is Austin.\"]\n",
    "\n",
    "# Calculate the Rouge score\n",
    "rouge_score = rouge.get_scores(hypothesis_text, reference_text)\n",
    "\n",
    "rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of dict to list of dict\n",
    "pd.json_normalize(rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(reversed(\"The capital of Texas is Austin.\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = [\n",
    "    \"Austin\",\n",
    "    \"The capital of Texas is Austin.\",\n",
    "    \"The capital of Texas is not Austin.\",\n",
    "    \"The capital of Texas is a city.\",\n",
    "    ' '.join(reversed(\"The capital of Texas is Austin.\".split())),\n",
    "    \"Texas has no capital.\",\n",
    "    \"The capital of Texas is Houston.\",\n",
    "    \"This is a great question. The capital of Texas is Austin.\",\n",
    "    \"The answer is Austin.\",\n",
    "    \"The capital of Texas is Austin, Texas.\",\n",
    "    \"In Texas, the capital is Austin.\",\n",
    "    \"Surely you know that the capital of Texas is Austin.\",\n",
    "    \"The capital of Texas is Austin, Texas, USA.\",\n",
    "    \"Based on my research, the capital of Texas is Austin.\",\n",
    "    \"The capital city of Texas is Austin.\",  \n",
    "    \"The capital city of Texas is Austin.\"+'.'*15,\n",
    "    \"The capital city of Texas is Austin. \"*5, \n",
    "    \"The capital city of Texas is Austin. \"*10\n",
    "    \n",
    "]\n",
    "\n",
    "references = [\n",
    "    \"The capital of Texas is Austin.\",\n",
    "    \"Austin is the capital of Texas.\",\n",
    "    \"The capital is Austin.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for hypothesis in hypotheses:\n",
    "    for reference in references:\n",
    "        rouge_score = rouge.get_scores(hypothesis, reference)\n",
    "        frame = pd.json_normalize(rouge_score)\n",
    "        frame[\"hypothesis\"] = hypothesis\n",
    "        frame['hypothesis_length'] = len(hypothesis.split())\n",
    "        frame[\"reference\"] = reference\n",
    "        frame['reference_length'] = len(reference.split())\n",
    "        results.append(frame)\n",
    "        \n",
    "        \n",
    "df = pd.concat(results)    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(regex='hypothesis|reference').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df.melt(id_vars=df.filter(regex='hypothesis|reference').columns, var_name=\"metric\", value_name=\"score\")\n",
    "df_long['type'] = df_long['metric'].str.split(\".\").str[-1]\n",
    "\n",
    "# difference in words\n",
    "df_long['length_difference'] = df_long['hypothesis_length'] - df_long['reference_length']\n",
    "\n",
    "# relative difference in words (kind of like %)\n",
    "df_long['length_difference_rel'] = df_long['length_difference'].abs() / df_long['reference_length']\n",
    "\n",
    "# df_long['score_scaled'] = df_long['score'] * (1-df_long['length_difference_rel'].abs())\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "df_long['score_scaled'] = df_long['score'] * np.exp(-df_long['length_difference_rel']**2)\n",
    "\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 3, 1000)\n",
    "y = np.exp(-x**2)\n",
    "px.line(x=x, y=y, width=800, height=600, template=\"plotly_white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(df_long, x=\"score\", facet_col=\"metric\",color=\"type\",\n",
    "             facet_col_wrap=3,\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_long, x=\"hypothesis_length\", y='score_scaled',\n",
    "           facet_col=\"metric\", color=\"type\", opacity=0.4,\n",
    "           hover_data=['hypothesis', 'reference'],\n",
    "             facet_col_wrap=3,\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_long, x=\"reference_length\", y='score_scaled',\n",
    "           facet_col=\"metric\", color=\"type\", opacity=0.4,\n",
    "           hover_data=['hypothesis', 'reference'],\n",
    "           \n",
    "             facet_col_wrap=3,\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_long, x=\"length_difference_rel\", y='score_scaled',\n",
    "           facet_col=\"metric\", color=\"type\", opacity=0.4,\n",
    "           hover_data=['hypothesis', 'reference','score','score_scaled'],\n",
    "           \n",
    "             facet_col_wrap=3,\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_long, x=\"length_difference\", y='score',\n",
    "           facet_col=\"metric\", color=\"type\", opacity=0.4,\n",
    "           hover_data=['hypothesis', 'reference'],\n",
    "           \n",
    "             facet_col_wrap=3,\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_long, x=\"hypothesis_length\", y='reference_length',\n",
    "           facet_col=\"metric\", color=\"score\", opacity=0.4,\n",
    "             facet_col_wrap=3, color_continuous_scale='BlueRed',\n",
    "            width=800, height=600, template='plotly_white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U angle-emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5039,  0.5862,  0.3513,  ..., -0.1364, -0.1045,  0.3366]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.7404,  0.5638,  0.1595,  ...,  0.1838, -0.2180,  0.0240],\n",
      "        [ 0.4121,  0.9849,  0.7677,  ..., -0.4061, -0.3609,  0.1150]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from angle_emb import AnglE\n",
    "\n",
    "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls').cuda()\n",
    "vec = angle.encode('hello world', to_numpy=False)\n",
    "print(vec)\n",
    "vecs = angle.encode(['hello world1', 'hello world2'], to_numpy=False)\n",
    "print(vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8936, 0.8851], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "# Assuming you have two sentence embeddings stored in `embedding1` and `embedding2`\n",
    "distance = cosine_similarity(vec, vecs)\n",
    "print(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_embeddings = angle.encode(hypotheses, to_numpy=False)\n",
    "\n",
    "hypothesis_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reference_embeddings = angle.encode(references, to_numpy=False)\n",
    "\n",
    "reference_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "\n",
    "for i, emb1 in enumerate(hypothesis_embeddings):\n",
    "    similarities = cosine_similarity(emb1.reshape(1,-1), reference_embeddings)\n",
    "    for j, score in enumerate(similarities):\n",
    "        r.append({'hyp': hypotheses[i], 'ref': references[j], 'score': score.item()})\n",
    "        \n",
    "    r.append({'hyp': hypotheses[i], 'ref': 'mean', 'score': similarities.mean().item()})\n",
    "    r.append({'hyp': hypotheses[i], 'ref': 'max', 'score': similarities.max().item()})\n",
    "    \n",
    "\n",
    "pd.DataFrame(r).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_embeddings.shape, reference_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rewards = ROUGE + Relevance + LengthMatch + Time\n",
    "\n",
    "ROUGE: Measure of how similar the generated text is to the reference text\n",
    "PROS: \n",
    "- Easy to implement\n",
    "- fast to compute\n",
    "CONS: \n",
    "- Does not take into account the meaning of the text\n",
    "- Does not take into account the grammar of the text (i.e word order, repetition, etc)\n",
    "\n",
    "Relevance: Measure of how relevant the generated text is to the input text using sentence embeddings\n",
    "PROS:\n",
    "- Takes into account the meaning of the text\n",
    "- Takes into account the grammar of the text(?)\n",
    "CONS:\n",
    "- Slow to compute\n",
    "- Susceptible to noise in the input text\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    \"In Inazuma Eleven GO 2: Chrono Stone, can you explain how the time travel mechanism works and how it allows players to manipulate the game's narrative and gameplay elements?\",\n",
    "    \"In Inazuma Eleven GO 2: Chrono Stone, the concept of time travel is introduced as a major plot element. The story follows the protagonist, Arion Sherwind, as he travels back in time to prevent a catastrophic event that threatens the future of soccer. Arion is aided by his childhood friend, Tenma Matsukaze, who also happens to be the main character from the previous game, Inazuma Eleven GO.\",\n",
    "]\n",
    "\n",
    "phrases_embeddings = angle.encode(phrases, to_numpy=False)\n",
    "\n",
    "cosine_similarity(phrases_embeddings[0].reshape(1,-1), phrases_embeddings[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holy shit that took only 0.019 seconds?!\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    'Physics',\n",
    "    'People',\n",
    "    'Lifestyle',\n",
    "    'Travel',\n",
    "    'Cooking',\n",
    "    'Geography',\n",
    "    'Music',\n",
    "    'Movies',\n",
    "    'Sports',\n",
    "    'Politics',\n",
    "    'History',\n",
    "    'Business',\n",
    "    'Mathematics',\n",
    "    'Science',\n",
    "    'Technology',\n",
    "    'Art',\n",
    "    'Literature',\n",
    "    'Philosophy',\n",
    "    'Religion and Spirituality',\n",
    "    'Health and Fitness',\n",
    "]\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "categories_embeddings = angle.encode(categories, to_numpy=False)\n",
    "print(f'Holy shit that took only {time.time()-t0:.3f} seconds?!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    'John is a very good football player. He plays for the New York Giants.',\n",
    "    'Plastic is a material consisting of any of a wide range of synthetic or semi-synthetic organic compounds that are malleable and can be molded into solid objects.',\n",
    "    'The United States of America (USA), commonly known as the United States (U.S. or US), or America, is a country primarily located in North America, consisting of 50 states, a federal district, five major self-governing territories, and various possessions.',\n",
    "    'The 2019–20 coronavirus pandemic is an ongoing pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak was first identified in Wuhan, Hubei, China, in December 2019, and was recognized as a pandemic by the World Health Organization (WHO) on 11 March 2020.',\n",
    "    'Salvador Domingo Felipe Jacinto Dalí i Domènech, 1st Marquess of Dalí de Púbol (11 May 1904 – 23 January 1989), known professionally as Salvador Dalí (/ˈdɑːli, dɑːˈliː/; Catalan: [səlβəˈðo ðəˈli], Spanish: [salβaˈðoɾ ðaˈli]), was a Spanish Surrealist artist renowned for his technical skill, precise draftsmanship and the striking and bizarre images in his work. Born in Figueres, Catalonia, Dalí received his formal education in fine arts at Madrid.',\n",
    "    'Children are not little adults. Pound for pound, kids are exposed to more contaminants in air, water, food, and personal care products than adults. Immature organ systems are often less capable of fending off chemical assaults. Subtle damage to developing bodies may lead to disease later in life.',\n",
    "    'Dirac fermions are fermions which occur as quasiparticles in condensed matter. They were first discussed by Paul Dirac in the context of electrons in graphene, which are described by the massless Dirac equation. Dirac fermions have since been realized experimentally in graphene and topological insulators, and are thought to occur in other materials.',\n",
    "    'If you believe in God, you believe in the existence of a supreme being, or God, who is worthy of our worship. If you believe in God, you believe that there is a supreme being who is worthy of our worship.',\n",
    "    'Singapore, officially the Republic of Singapore, is a sovereign island city-state in maritime Southeast Asia. It lies about one degree of latitude (137 kilometres or 85 miles) north of the equator, off the southern tip of the Malay Peninsula, bordering the Straits of Malacca to the west, the Riau Islands (Indonesia) to the south, and the South China Sea to the east.',\n",
    "    'Robin Williams, in full Robin McLaurin Williams, (born July 21, 1951, Chicago, Illinois, U.S.—died August 11, 2014, Tiburon, California), American comedian and actor known for his manic stand-up routines and his diverse film performances. He won an Academy Award for his role in Good Will Hunting (1997).',\n",
    "    'The battle of Hastings was fought on 14 October 1066 between the Norman-French army of William, the Duke of Normandy, and an English army under the Anglo-Saxon King Harold Godwinson, beginning the Norman conquest of England. It took place approximately 7 miles (11 kilometres) northwest of Hastings, close to the present-day town of Battle, East Sussex, and was a decisive Norman victory.',\n",
    "]\n",
    "\n",
    "documents_embeddings = angle.encode(documents, to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John is a very good football player. He plays for the New York Giants.\n",
      "['Sports']\n",
      "Holy shit that took only 0.019 seconds?!\n",
      "\n",
      "Plastic is a material consisting of any of a wide range of synthetic or semi-synthetic organic compounds that are malleable and can be molded into solid objects.\n",
      "['Science', 'Technology']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "The United States of America (USA), commonly known as the United States (U.S. or US), or America, is a country primarily located in North America, consisting of 50 states, a federal district, five major self-governing territories, and various possessions.\n",
      "['People', 'Geography']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "The 2019–20 coronavirus pandemic is an ongoing pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak was first identified in Wuhan, Hubei, China, in December 2019, and was recognized as a pandemic by the World Health Organization (WHO) on 11 March 2020.\n",
      "No tags found for document. Closest match: People\n",
      "['Other']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "Salvador Domingo Felipe Jacinto Dalí i Domènech, 1st Marquess of Dalí de Púbol (11 May 1904 – 23 January 1989), known professionally as Salvador Dalí (/ˈdɑːli, dɑːˈliː/; Catalan: [səlβəˈðo ðəˈli], Spanish: [salβaˈðoɾ ðaˈli]), was a Spanish Surrealist artist renowned for his technical skill, precise draftsmanship and the striking and bizarre images in his work. Born in Figueres, Catalonia, Dalí received his formal education in fine arts at Madrid.\n",
      "['Art']\n",
      "Holy shit that took only 0.019 seconds?!\n",
      "\n",
      "Children are not little adults. Pound for pound, kids are exposed to more contaminants in air, water, food, and personal care products than adults. Immature organ systems are often less capable of fending off chemical assaults. Subtle damage to developing bodies may lead to disease later in life.\n",
      "['People', 'Health and Fitness']\n",
      "Holy shit that took only 0.016 seconds?!\n",
      "\n",
      "Dirac fermions are fermions which occur as quasiparticles in condensed matter. They were first discussed by Paul Dirac in the context of electrons in graphene, which are described by the massless Dirac equation. Dirac fermions have since been realized experimentally in graphene and topological insulators, and are thought to occur in other materials.\n",
      "['Physics']\n",
      "Holy shit that took only 0.016 seconds?!\n",
      "\n",
      "If you believe in God, you believe in the existence of a supreme being, or God, who is worthy of our worship. If you believe in God, you believe that there is a supreme being who is worthy of our worship.\n",
      "['Philosophy', 'Religion and Spirituality']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "Singapore, officially the Republic of Singapore, is a sovereign island city-state in maritime Southeast Asia. It lies about one degree of latitude (137 kilometres or 85 miles) north of the equator, off the southern tip of the Malay Peninsula, bordering the Straits of Malacca to the west, the Riau Islands (Indonesia) to the south, and the South China Sea to the east.\n",
      "['Geography']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "Robin Williams, in full Robin McLaurin Williams, (born July 21, 1951, Chicago, Illinois, U.S.—died August 11, 2014, Tiburon, California), American comedian and actor known for his manic stand-up routines and his diverse film performances. He won an Academy Award for his role in Good Will Hunting (1997).\n",
      "No tags found for document. Closest match: Movies\n",
      "['Other']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n",
      "The battle of Hastings was fought on 14 October 1066 between the Norman-French army of William, the Duke of Normandy, and an English army under the Anglo-Saxon King Harold Godwinson, beginning the Norman conquest of England. It took place approximately 7 miles (11 kilometres) northwest of Hastings, close to the present-day town of Battle, East Sussex, and was a decisive Norman victory.\n",
      "No tags found for document. Closest match: History\n",
      "['Other']\n",
      "Holy shit that took only 0.017 seconds?!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_tags(document, categories_embeddings, n=1, threshold=0.5):\n",
    "    document_embedding = angle.encode(document, to_numpy=False)\n",
    "    similarities = cosine_similarity(document_embedding.reshape(1,-1), categories_embeddings)\n",
    "    if n is not None:\n",
    "        tags = [categories[i] for i in similarities.argsort()[-n:]]\n",
    "    else:\n",
    "        tags = [categories[i] for i, similarity in enumerate(similarities) if similarity >= threshold]\n",
    "    if not tags:\n",
    "        closest_match = similarities.argmax()\n",
    "        print(f'No tags found for document. Closest match: {categories[closest_match]}')\n",
    "        tags = ['Other']\n",
    "    return tags\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc)\n",
    "    t0 = time.time()\n",
    "    print(get_tags(doc, categories_embeddings,n=None))\n",
    "    print(f'Holy shit that took only {time.time()-t0:.3f} seconds?!')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
